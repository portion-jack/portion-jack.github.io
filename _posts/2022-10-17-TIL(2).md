---
layout: post
title: Today I learned(2022_10_17)(2)
date: 2022-10-17
tags: [TIL, api, crawling, xml]
toc:  true
---
서울시 열린데이터 광장에서 실시간 서울 api를 받아온다.<br/>
json에 익숙하지만 xml을 파싱하는 방법과 xmltodict라는 괜찮은 라이브러리를 사용한다.<br/>
{: .message }

## crawling
## 서울시의 특정지역은 인구밀도
### 인구밀도를 나이대까지 세분화 하여 얻을 수 있다
### 꾸준히 db에 쌓는다면 큰 의미가 있을지도 모른다.


```
import numpy as np
import pandas as pd

import requests
from bs4 import BeautifulSoup

import xmltodict


def seoul_location_api(my_api, location):
    response = requests.get(f"http://openapi.seoul.go.kr:8088/{my_api}/xml/citydata/1/5/{location}")
    raw_xml = response.content
    parsed_xml = BeautifulSoup(raw_xml, "lxml")
    return parsed_xml


def population_dict(parsed_xml):
    ppl_xml = parsed_xml.find('live_ppltn_stts').find('live_ppltn_stts')
    ppl_dict = xmltodict.parse(str(ppl_xml))
    ppl_main_dict = ppl_dict['live_ppltn_stts']
    return ppl_main_dict


def dict2df(_dict):
    try:
        result = pd.DataFrame(_dict)
        return result
    except:
        data = np.array(list(data.values())).reshape(1, -1)
        columns = list(data.keys())
        result = pd.DataFrame(data=data, columns=columns)
        return result
```
